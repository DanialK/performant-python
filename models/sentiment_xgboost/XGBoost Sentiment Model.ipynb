{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import joblib\n",
    "import re\n",
    "import pickle\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_balanced = feather.read_dataframe(\"../../data/balanced_reviews.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_1</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>wOv7JiO0EGcJ61P2JcDS1g</td>\n",
       "      <td>en0xQXlvRk-ZtKlaW4I8eQ</td>\n",
       "      <td>N0apJkxIem2E8irTBRKnHw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Went here last weekend and was pretty disappoi...</td>\n",
       "      <td>2015-01-18 15:30:50</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>UIvFkXLBxWxM6aekvaCp8Q</td>\n",
       "      <td>0FMte0z-repSVWSJ_BaQTg</td>\n",
       "      <td>WsdmzI2giWHcRN2plprxIg</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>Took my kids here to hang out on one fine 72 d...</td>\n",
       "      <td>2013-05-28 21:06:57</td>\n",
       "      <td>2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>qdQIIf6xuyubxEG05e02TA</td>\n",
       "      <td>XPZVfP7DQCSL3Nb9t2vxsA</td>\n",
       "      <td>1HD5iUUfVJDbfEBIn9yVhw</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes... the Boba Tea explosion is in full force...</td>\n",
       "      <td>2017-03-15 02:02:13</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>h7Rmb3EiXjajVfGYNa5CuQ</td>\n",
       "      <td>oAOE4UAC5ZbAjEGBEMCb4g</td>\n",
       "      <td>PycR_Mr5jA9jB4Xg3nX0Yw</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>They charged me twice what I expected to pay. ...</td>\n",
       "      <td>2014-01-17 02:15:25</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>VRlBw70YHxje2n42IEOw6w</td>\n",
       "      <td>n5lEgdrkMlQd0_myn51j9g</td>\n",
       "      <td>01o6K5ID_vW8tXZ7QAzPJg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PRC consulted on 2 tile roof replacements at a...</td>\n",
       "      <td>2017-11-06 17:58:01</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_1  stars               review_id                 user_id  \\\n",
       "0       35      2  wOv7JiO0EGcJ61P2JcDS1g  en0xQXlvRk-ZtKlaW4I8eQ   \n",
       "1       57      2  UIvFkXLBxWxM6aekvaCp8Q  0FMte0z-repSVWSJ_BaQTg   \n",
       "2       75      5  qdQIIf6xuyubxEG05e02TA  XPZVfP7DQCSL3Nb9t2vxsA   \n",
       "3      100      1  h7Rmb3EiXjajVfGYNa5CuQ  oAOE4UAC5ZbAjEGBEMCb4g   \n",
       "4      105      5  VRlBw70YHxje2n42IEOw6w  n5lEgdrkMlQd0_myn51j9g   \n",
       "\n",
       "              business_id  useful  funny  cool  \\\n",
       "0  N0apJkxIem2E8irTBRKnHw       0      0     0   \n",
       "1  WsdmzI2giWHcRN2plprxIg       5     14     4   \n",
       "2  1HD5iUUfVJDbfEBIn9yVhw      11      8    11   \n",
       "3  PycR_Mr5jA9jB4Xg3nX0Yw      14      1     1   \n",
       "4  01o6K5ID_vW8tXZ7QAzPJg       0      0     0   \n",
       "\n",
       "                                                text                date   len  \n",
       "0  Went here last weekend and was pretty disappoi... 2015-01-18 15:30:50   815  \n",
       "1  Took my kids here to hang out on one fine 72 d... 2013-05-28 21:06:57  2072  \n",
       "2  Yes... the Boba Tea explosion is in full force... 2017-03-15 02:02:13  1012  \n",
       "3  They charged me twice what I expected to pay. ... 2014-01-17 02:15:25   709  \n",
       "4  PRC consulted on 2 tile roof replacements at a... 2017-11-06 17:58:01   442  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[[self.field]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=stop_words,\n",
    "                     min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('len')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "    ])),\n",
    "    ('clf', XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rev_balanced[['text', 'len']]\n",
    "Y = df_rev_balanced['stars'].apply(lambda x: 1 if x > 3 else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danial/dev/performant-python-services/venv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', 'onc', 'onli', 'ourselv', 'themselv', 'thi', 'veri', 'wa', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "model = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.57%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {round((predictions == y_test).mean() * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = [\"I love my mother\"]\n",
    "import pandas as pd\n",
    "sample_X = pd.DataFrame()\n",
    "sample_X['text'] = samples\n",
    "sample_X['len'] = [len(x.split()) for x in samples]\n",
    "# sample_X.head()\n",
    "[\"Positive\" if prediction == 1 else \"Negative\" for prediction in model.predict(sample_X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../../assets/sentiment_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../assets/sentiment_xgboost/model.joblib.dat']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"../../assets/sentiment_xgboost/model.joblib.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline\n",
    "pickle.dump(model, open(\"../../assets/sentiment_xgboost/model.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the xgboost booster\n",
    "classifier = model.steps[1][1]\n",
    "classifier._Booster.save_model(\"../../assets/sentiment_xgboost/classifier.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
